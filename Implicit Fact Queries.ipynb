{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "338c95bd",
   "metadata": {},
   "source": [
    "## Multi-Hop RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f14fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "from typing import List, Dict, Any\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SimpleField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SearchableField,\n",
    "    VectorSearch,\n",
    "    VectorSearchProfile,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    VectorSearchAlgorithmMetric,\n",
    "    HnswParameters,\n",
    "    SemanticSearch,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField\n",
    ")\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "import time\n",
    "\n",
    "\n",
    "# Replace with your actual Azure Cognitive Search endpoint and admin key\n",
    "\n",
    "\n",
    "AZURE_SEARCH_ENDPOINT = \"https://.search.windows.net\"\n",
    "AZURE_SEARCH_KEY =  \"\"\n",
    "credential = AzureKeyCredential(AZURE_SEARCH_KEY)\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key = \"\",  \n",
    "    api_version = \"2024-02-01\",\n",
    "    azure_endpoint = \"https://.openai.azure.com/\" \n",
    ")\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "GPT_DEPLOYMENT_NAME = \"gpt-4o\"  # or your Azure GPT deployment\n",
    "\n",
    "# 2. Create the Search Clients\n",
    "INDEX_NAME = \"product-documents-index\"\n",
    "search_index_client = SearchIndexClient(endpoint=AZURE_SEARCH_ENDPOINT, credential=credential)\n",
    "search_client = SearchClient(endpoint=AZURE_SEARCH_ENDPOINT, index_name=INDEX_NAME, credential=credential)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1961b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings_for_docs(texts: list[str]) -> list[list[float]]:\n",
    "    # 'client' is your AzureOpenAI or OpenAI client\n",
    "    response = client.embeddings.create(\n",
    "        model=EMBEDDING_MODEL_NAME,\n",
    "        input=texts\n",
    "    )\n",
    "    return [item.embedding for item in response.data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe9d0173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final multi-hop answer:\n",
      " Azure AI Search uses embeddings to enable semantic search, which enhances search capabilities by understanding the context and meaning behind search queries and documents, rather than just matching keywords. This is achieved through vector search, where text is converted into dense vector representations that capture semantic meaning, allowing for more accurate and relevant search results.\n",
      "\n",
      "To set up Azure AI Search for semantic search, follow these steps:\n",
      "\n",
      "1. **Provision Azure Cognitive Search Service**: \n",
      "   - Go to the Azure portal.\n",
      "   - Select \"Create a resource\" and search for \"Azure Cognitive Search\".\n",
      "   - Click \"Create\" and fill in the required details such as the subscription, resource group, and service name.\n",
      "   - Choose the pricing tier and region.\n",
      "   - Review and create the service.\n",
      "\n",
      "2. **Create and Configure an Index**:\n",
      "   - Define the schema for your search index, including fields that will store the embeddings.\n",
      "   - Set up indexes by defining the schema, including fields and data types.\n",
      "   - Upload data to the index using data sources like Azure SQL Database, Cosmos DB, or Azure Blob Storage.\n",
      "   - Configure indexers to automate data ingestion and updates.\n",
      "   - Utilize built-in AI capabilities such as cognitive skills for enriching the data.\n",
      "\n",
      "3. **Generate Embeddings**:\n",
      "   - Use Azure OpenAI or another service to generate embeddings for your documents and queries.\n",
      "\n",
      "4. **Upload Data**:\n",
      "   - Ingest your documents and their corresponding embeddings into the search index.\n",
      "\n",
      "5. **Implement Search Queries\n"
     ]
    }
   ],
   "source": [
    "def multi_hop_rag(query: str, max_steps: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Multi-hop retrieval: \n",
    "      1. Decompose the question into sub-questions (chain-of-thought).\n",
    "      2. Retrieve context for each sub-question.\n",
    "      3. Generate partial answers and synthesize final answer.\n",
    "    \"\"\"\n",
    "\n",
    "    decomposition_prompt = (\n",
    "        \"You are an expert at breaking down complex questions. \"\n",
    "        \"Given the user question, list a few sub-questions (up to {max_steps}) \"\n",
    "        \"that need to be answered to arrive at a final answer.\\n\\n\"\n",
    "        f\"Question: {query}\\n\\n\"\n",
    "        \"Sub-questions:\"\n",
    "    )\n",
    "\n",
    "    decomposition_response = client.chat.completions.create(\n",
    "        model=GPT_DEPLOYMENT_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": decomposition_prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=300\n",
    "    )\n",
    "\n",
    "    decomposition_text = decomposition_response.choices[0].message.content\n",
    "  \n",
    "    sub_questions = [line.strip() for line in decomposition_text.split(\"\\n\") if line.strip()]\n",
    "    \n",
    "    partial_answers = []\n",
    "    \n",
    "    for sq_index, subq in enumerate(sub_questions, start=1):\n",
    "        clean_subq = subq.strip(\"1234567890). \")\n",
    "        if not clean_subq:\n",
    "            continue\n",
    "\n",
    "        # Vector retrieval\n",
    "        query_embedding = generate_embeddings_for_docs([clean_subq])[0]  \n",
    "        vector_query = VectorizedQuery(\n",
    "            vector=query_embedding,\n",
    "            k_nearest_neighbors=3,\n",
    "            fields=\"content_vector\"\n",
    "        )\n",
    "        results = search_client.search(\n",
    "            search_text=None,\n",
    "            vector_queries=[vector_query],\n",
    "            select=[\"title\", \"text\", \"url\"]\n",
    "        )\n",
    "\n",
    "        retrieved_texts = []\n",
    "        for result in results:\n",
    "            snippet = f\"Title: {result['title']}\\nText: {result['text']}\\nURL: {result['url']}\"\n",
    "            retrieved_texts.append(snippet)\n",
    "        context_str = \"\\n\\n\".join(retrieved_texts)\n",
    "\n",
    "        partial_prompt = (\n",
    "            f\"Sub-question: {clean_subq}\\n\\n\"\n",
    "            \"Relevant context:\\n\"\n",
    "            f\"{context_str}\\n\\n\"\n",
    "            \"Provide a brief factual answer:\"\n",
    "        )\n",
    "\n",
    "        partial_response = client.chat.completions.create(\n",
    "            model=GPT_DEPLOYMENT_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You answer based on context. If unsure, say 'not sure'.\"},\n",
    "                {\"role\": \"user\", \"content\": partial_prompt}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            max_tokens=200\n",
    "        )\n",
    "\n",
    "        partial_answer = partial_response.choices[0].message.content.strip()\n",
    "        partial_answers.append((clean_subq, partial_answer))\n",
    "\n",
    "    synthesis_context = \"\\n\".join([f\"Q: {sq}\\nA: {ans}\" for sq, ans in partial_answers])\n",
    "    final_prompt = (\n",
    "        f\"The user asked: {query}\\n\\n\"\n",
    "        \"We have the following partial answers from each sub-question:\\n\"\n",
    "        f\"{synthesis_context}\\n\\n\"\n",
    "        \"Now synthesize a final answer to the original question as best as possible.\"\n",
    "    )\n",
    "\n",
    "    synthesis_response = client.chat.completions.create(\n",
    "        model=GPT_DEPLOYMENT_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a thoughtful assistant. Combine partial answers to respond fully.\"},\n",
    "            {\"role\": \"user\", \"content\": final_prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=300\n",
    "    )\n",
    "\n",
    "    final_answer = synthesis_response.choices[0].message.content.strip()\n",
    "    return final_answer\n",
    "\n",
    "complex_question = \"How does Azure AI Search use embeddings, and what steps are needed to set it up for semantic search?\"\n",
    "answer = multi_hop_rag(complex_question)\n",
    "print(\"Final multi-hop answer:\\n\", answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9de8de",
   "metadata": {},
   "source": [
    "## IRCoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97f1ed31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== ITERATION: 0\n",
      "------ NEED: How does Azure AI Search use embeddings? \n",
      "\n",
      "NEED: Do I need to enable vector search in Azure AI Search? \n",
      "\n",
      "NEED: What are the steps to set up semantic configuration in Azure AI Search?\n",
      "*************** conversation: [{'role': 'system', 'content': \"You are a chain-of-thought reasoner with the ability to request additional context.\\nIf you need more context, write: 'NEED: <subquestion>'.\\nWhen you have enough info, finalize with: 'DONE: <final answer>'.\\n\\nImportant: The user only sees your final answer (after 'DONE:'). Your chain-of-thought and 'NEED:' lines are hidden from the user.\\n\"}, {'role': 'user', 'content': 'User question: Explain how Azure AI Search uses embeddings, and if I need to enable vector search. Then tell me the steps to set up semantic configuration.'}, {'role': 'assistant', 'content': 'NEED: How does Azure AI Search use embeddings? \\n\\nNEED: Do I need to enable vector search in Azure AI Search? \\n\\nNEED: What are the steps to set up semantic configuration in Azure AI Search?'}, {'role': 'system', 'content': \"Here is additional context for your subquestion 'How does Azure AI Search use embeddings? \\n\\nNEED: Do I need to enable vector search in Azure AI Search? \\n\\nNEED: What are the steps to set up semantic configuration in Azure AI Search?':\\n\\nTitle: Azure AI Search Overview\\nText: Azure AI Search is a search-as-a-service solution with built-in AI capabilities for cloud apps... \\n                   It provides both full-text search using BM25 and vector search using embeddings...\\n\\nTitle: Azure OpenAI Introduction\\nText: Azure OpenAI offers access to advanced language models like GPT, enabling developers to build intelligent apps...\\n                   Embeddings allow for semantic understanding, powering advanced search solutions.\\n\\nYou can now continue your chain-of-thought.\"}]\n",
      "====== ITERATION: 1\n",
      "===== FINAL ANSWER =====\n",
      "Azure AI Search uses embeddings to enable semantic understanding of the content, which enhances the search capabilities by allowing for more relevant and context-aware search results. This is achieved through vector search, which uses these embeddings to find similar items based on their semantic meaning rather than just keyword matching.\n",
      "\n",
      "To enable vector search in Azure AI Search, you need to ensure that your search service is configured to use embeddings. This typically involves setting up a semantic configuration.\n",
      "\n",
      "Here are the steps to set up semantic configuration in Azure AI Search:\n",
      "1. **Create or Update Index**: Define an index schema that includes fields for storing the embeddings.\n",
      "2. **Enable Semantic Search**: In the search service, enable semantic search capabilities.\n",
      "3. **Generate Embeddings**: Use Azure AI or Azure OpenAI to generate embeddings for your documents and store them in the index.\n",
      "4. **Configure Semantic Settings**: Define the semantic configuration in your search service, specifying which fields to use for semantic search and how to process queries.\n",
      "5. **Query with Semantic Search**: Use the search API to perform queries that leverage the semantic configuration, providing more relevant search results based on the embeddings.\n",
      "\n",
      "By following these steps, you can set up and utilize the powerful semantic search capabilities provided by Azure AI Search.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "from typing import List, Dict, Any\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "\n",
    "\n",
    "AZURE_OPENAI_API_KEY = \"\"\n",
    "AZURE_OPENAI_ENDPOINT = \"https://.openai.azure.com/\" \n",
    "AZURE_OPENAI_API_VERSION = \"2024-02-01\"\n",
    "GPT_MODEL_DEPLOYMENT = \"gpt-4o\"\n",
    "\n",
    "# Azure Cognitive Search\n",
    "INDEX_NAME = \"product-documents-index\"\n",
    "search_index_client = SearchIndexClient(endpoint=AZURE_SEARCH_ENDPOINT, credential=credential)\n",
    "search_client = SearchClient(endpoint=AZURE_SEARCH_ENDPOINT, index_name=INDEX_NAME, credential=credential)\n",
    "\n",
    "# Initialize the AzureOpenAI client\n",
    "openai.api_type = \"azure\" \n",
    "client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=AZURE_OPENAI_API_VERSION\n",
    ")\n",
    "\n",
    "def generate_embeddings_for_query(query: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    For a single query string, return exactly one embedding list of floats.\n",
    "    \"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-ada-002\", \n",
    "        input=[query]\n",
    "    )\n",
    "    return response.data[0].embedding \n",
    "\n",
    "def retrieve_subquestion_context(subquestion: str, top_k: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve relevant context from Azure Cognitive Search using vector-based retrieval.\n",
    "    Returns a concatenated string of top documents.\n",
    "    \"\"\"\n",
    "    embedding = generate_embeddings_for_query(subquestion)\n",
    "    vector_query = VectorizedQuery(\n",
    "        vector=embedding,\n",
    "        k_nearest_neighbors=top_k,\n",
    "        fields=\"content_vector\"  \n",
    "    )\n",
    "    results = search_client.search(\n",
    "        search_text=None,\n",
    "        vector_queries=[vector_query],\n",
    "        select=[\"title\", \"text\"]\n",
    "    )\n",
    "\n",
    "    docs = []\n",
    "    for r in results:\n",
    "        doc_text = f\"Title: {r['title']}\\nText: {r['text']}\"\n",
    "        docs.append(doc_text)\n",
    "    return \"\\n\\n\".join(docs)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. IRCoT IMPLEMENTATION\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def ircot(question: str, max_iterations: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Iterative Retrieval Chain-of-Thought (IRCoT):\n",
    "      - The model can explicitly request more info by outputting 'NEED: <subquestion>'\n",
    "      - Once satisfied, it outputs 'DONE: <final answer>'\n",
    "      - We feed retrieved context to the model in subsequent iterations until 'DONE' is reached or we exceed max_iterations.\n",
    "    \"\"\"\n",
    "    conversation = []\n",
    "    system_instructions = (\n",
    "        \"You are a chain-of-thought reasoner with the ability to request additional context.\\n\"\n",
    "        \"If you need more context, write: 'NEED: <subquestion>'.\\n\"\n",
    "        \"When you have enough info, finalize with: 'DONE: <final answer>'.\\n\\n\"\n",
    "        \"Important: The user only sees your final answer (after 'DONE:'). \"\n",
    "        \"Your chain-of-thought and 'NEED:' lines are hidden from the user.\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "    conversation.append({\"role\": \"system\", \"content\": system_instructions})\n",
    "\n",
    "    conversation.append({\"role\": \"user\", \"content\": f\"User question: {question}\"})\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        print(\"====== ITERATION: \" + str(iteration))\n",
    "        # Call the model\n",
    "        response = client.chat.completions.create(\n",
    "            model=GPT_MODEL_DEPLOYMENT,\n",
    "            messages=conversation,\n",
    "            temperature=0.2,\n",
    "            max_tokens=400\n",
    "        )\n",
    "        assistant_reply = response.choices[0].message.content.strip()\n",
    "\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
    "\n",
    "        if \"NEED:\" in assistant_reply:\n",
    "            \n",
    "       \n",
    "            idx = assistant_reply.find(\"NEED:\") + len(\"NEED:\")\n",
    "            subquestion = assistant_reply[idx:].strip()\n",
    "            print(\"------ NEED: \" + subquestion)\n",
    "            \n",
    "            # Retrieve context from Azure Search\n",
    "            retrieved_text = retrieve_subquestion_context(subquestion)\n",
    "\n",
    "       \n",
    "            context_msg = (\n",
    "                f\"Here is additional context for your subquestion '{subquestion}':\\n\\n\"\n",
    "                f\"{retrieved_text}\\n\\n\"\n",
    "                \"You can now continue your chain-of-thought.\"\n",
    "            )\n",
    "            conversation.append({\"role\": \"system\", \"content\": context_msg})\n",
    "            print(\"*************** conversation: \" + str(conversation))\n",
    "\n",
    "        elif \"DONE:\" in assistant_reply:\n",
    "            idx = assistant_reply.find(\"DONE:\") + len(\"DONE:\")\n",
    "            final_answer = assistant_reply[idx:].strip()\n",
    "            return final_answer  # End the IRCoT loop\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return \"I'm sorry, I couldn't arrive at a final answer within the iteration limit.\"\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. EXAMPLE USAGE\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    complex_query = (\n",
    "        \"Explain how Azure AI Search uses embeddings, and if I need to enable vector search. \"\n",
    "        \"Then tell me the steps to set up semantic configuration.\"\n",
    "    )\n",
    "\n",
    "    final_answer = ircot(complex_query, max_iterations=5)\n",
    "    print(\"===== FINAL ANSWER =====\")\n",
    "    print(final_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28144df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== ITERATION: 0\n",
      "------ NEED: What specific context or application are you referring to for chunking (e.g., text processing, memory improvement, data analysis)?\n",
      "*************** conversation: [{'role': 'system', 'content': \"You are a chain-of-thought reasoner with the ability to request additional context.\\nIf you need more context, write: 'NEED: <subquestion>'.\\nWhen you have enough info, finalize with: 'DONE: <final answer>'.\\n\\nImportant: The user only sees your final answer (after 'DONE:'). Your chain-of-thought and 'NEED:' lines are hidden from the user.\\n\"}, {'role': 'user', 'content': \"User question: What's the best chunking strategy?\"}, {'role': 'assistant', 'content': 'NEED: What specific context or application are you referring to for chunking (e.g., text processing, memory improvement, data analysis)?'}, {'role': 'system', 'content': \"Here is additional context for your subquestion 'What specific context or application are you referring to for chunking (e.g., text processing, memory improvement, data analysis)?':\\n\\nTitle: Azure OpenAI Introduction\\nText: Azure OpenAI offers access to advanced language models like GPT, enabling developers to build intelligent apps...\\n                   Embeddings allow for semantic understanding, powering advanced search solutions.\\n\\nTitle: Azure AI Search Overview\\nText: Azure AI Search is a search-as-a-service solution with built-in AI capabilities for cloud apps... \\n                   It provides both full-text search using BM25 and vector search using embeddings...\\n\\nYou can now continue your chain-of-thought.\"}]\n",
      "====== ITERATION: 1\n",
      "------ NEED: Is the chunking strategy you are asking about related to text processing for search solutions or embeddings in Azure AI?\n",
      "*************** conversation: [{'role': 'system', 'content': \"You are a chain-of-thought reasoner with the ability to request additional context.\\nIf you need more context, write: 'NEED: <subquestion>'.\\nWhen you have enough info, finalize with: 'DONE: <final answer>'.\\n\\nImportant: The user only sees your final answer (after 'DONE:'). Your chain-of-thought and 'NEED:' lines are hidden from the user.\\n\"}, {'role': 'user', 'content': \"User question: What's the best chunking strategy?\"}, {'role': 'assistant', 'content': 'NEED: What specific context or application are you referring to for chunking (e.g., text processing, memory improvement, data analysis)?'}, {'role': 'system', 'content': \"Here is additional context for your subquestion 'What specific context or application are you referring to for chunking (e.g., text processing, memory improvement, data analysis)?':\\n\\nTitle: Azure OpenAI Introduction\\nText: Azure OpenAI offers access to advanced language models like GPT, enabling developers to build intelligent apps...\\n                   Embeddings allow for semantic understanding, powering advanced search solutions.\\n\\nTitle: Azure AI Search Overview\\nText: Azure AI Search is a search-as-a-service solution with built-in AI capabilities for cloud apps... \\n                   It provides both full-text search using BM25 and vector search using embeddings...\\n\\nYou can now continue your chain-of-thought.\"}, {'role': 'assistant', 'content': 'NEED: Is the chunking strategy you are asking about related to text processing for search solutions or embeddings in Azure AI?'}, {'role': 'system', 'content': \"Here is additional context for your subquestion 'Is the chunking strategy you are asking about related to text processing for search solutions or embeddings in Azure AI?':\\n\\nTitle: Azure AI Search Overview\\nText: Azure AI Search is a search-as-a-service solution with built-in AI capabilities for cloud apps... \\n                   It provides both full-text search using BM25 and vector search using embeddings...\\n\\nTitle: Azure OpenAI Introduction\\nText: Azure OpenAI offers access to advanced language models like GPT, enabling developers to build intelligent apps...\\n                   Embeddings allow for semantic understanding, powering advanced search solutions.\\n\\nYou can now continue your chain-of-thought.\"}]\n",
      "====== ITERATION: 2\n",
      "===== FINAL ANSWER =====\n",
      "The best chunking strategy for text processing in search solutions or embeddings in Azure AI involves breaking down the text into semantically meaningful units. This can be achieved by:\n",
      "\n",
      "1. **Sentence-Level Chunking**: Splitting the text into individual sentences to maintain context and coherence.\n",
      "2. **Paragraph-Level Chunking**: Dividing the text into paragraphs if the sentences are too short or if more context is needed.\n",
      "3. **Fixed-Length Chunking**: Creating chunks of a fixed number of tokens or words, ensuring they do not exceed model input limits.\n",
      "4. **Semantic Chunking**: Using natural language processing techniques to identify and split text based on semantic boundaries, such as topics or subtopics.\n",
      "\n",
      "This approach ensures that each chunk is meaningful and can be effectively processed by search algorithms or embeddings for better search results and semantic understanding.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    complex_query = (\n",
    "        \"What's the best chunking strategy?\"\n",
    "     \n",
    "    )\n",
    "\n",
    "    final_answer = ircot(complex_query, max_iterations=5)\n",
    "    print(\"------ FINAL ANSWER ------\")\n",
    "    print(final_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c45cfbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
