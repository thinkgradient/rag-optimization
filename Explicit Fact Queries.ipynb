{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ecdd77e",
   "metadata": {},
   "source": [
    "## Explicit Fact Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f10f8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index product-documents-index created/updated successfully.\n",
      "Upload result: [<azure.search.documents._generated.models._models_py3.IndexingResult object at 0x0000019B59C9E450>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x0000019B59C9DF10>]\n",
      "Title: Azure AI Search Overview\n",
      "Score: 0.9084782\n",
      "URL: https://docs.microsoft.com/en-us/azure/search\n",
      "\n",
      "Title: Azure OpenAI Introduction\n",
      "Score: 0.8701985\n",
      "URL: https://docs.microsoft.com/en-us/azure/openai\n",
      "\n",
      "\n",
      "Generated Answer:\n",
      "Azure AI Search offers a search-as-a-service solution with built-in AI capabilities for cloud apps. It provides both full-text search using BM25 and vector search using embeddings.\n",
      "--- Iteration 1 ---\n",
      "Answer at iteration 1:\n",
      "To use Azure AI Search for vector search, you can leverage the built-in AI capabilities that support embeddings. Here’s a general approach to using Azure AI Search for vector search:\n",
      "\n",
      "1. **Generate Embeddings**: Use a model, such as those provided by Azure OpenAI, to generate embeddings for your documents. Embeddings are numerical representations of the semantic content of the text.\n",
      "\n",
      "2. **Indexing**: Index these embeddings in Azure AI Search. This involves creating a search index that can store and retrieve these vector representations.\n",
      "\n",
      "3. **Querying**: When performing a search, convert the query into an embedding using the same model. This ensures that the query and the documents are represented in the same vector space.\n",
      "\n",
      "4. **Vector Search**: Use the vector search capabilities of Azure AI Search to find documents whose embeddings are most similar to the query embedding. This typically involves calculating the cosine similarity or another distance metric between the query embedding and the document embeddings.\n",
      "\n",
      "By following these steps, you can leverage Azure AI Search to perform advanced vector searches, enabling more accurate and semantically meaningful search results.\n",
      "\n",
      "Final Answer: To use Azure AI Search for vector search, you can leverage the built-in AI capabilities that support embeddings. Here’s a general approach to using Azure AI Search for vector search:\n",
      "\n",
      "1. **Generate Embeddings**: Use a model, such as those provided by Azure OpenAI, to generate embeddings for your documents. Embeddings are numerical representations of the semantic content of the text.\n",
      "\n",
      "2. **Indexing**: Index these embeddings in Azure AI Search. This involves creating a search index that can store and retrieve these vector representations.\n",
      "\n",
      "3. **Querying**: When performing a search, convert the query into an embedding using the same model. This ensures that the query and the documents are represented in the same vector space.\n",
      "\n",
      "4. **Vector Search**: Use the vector search capabilities of Azure AI Search to find documents whose embeddings are most similar to the query embedding. This typically involves calculating the cosine similarity or another distance metric between the query embedding and the document embeddings.\n",
      "\n",
      "By following these steps, you can leverage Azure AI Search to perform advanced vector searches, enabling more accurate and semantically meaningful search results.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Azure Cognitive Search Imports\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SimpleField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SearchableField,\n",
    "    VectorSearch,\n",
    "    VectorSearchProfile,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    VectorSearchAlgorithmMetric,\n",
    "    HnswParameters,\n",
    "    SemanticSearch,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 1. CONFIGURATION\n",
    "# ----------------------------\n",
    "\n",
    "# Replace with your actual Azure Cognitive Search endpoint and admin key\n",
    "AZURE_SEARCH_ENDPOINT = \"https://.search.windows.net\"\n",
    "AZURE_SEARCH_KEY =  \"\"\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key = \"\",  \n",
    "  api_version = \"2024-02-01\",\n",
    "  azure_endpoint = \"https://.openai.azure.com/\" \n",
    ")\n",
    "\n",
    "# Index name to store documents\n",
    "INDEX_NAME = \"product-documents-index\"\n",
    "\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"  # e.g. \"text-embedding-ada-002\" or your custom Azure deployment\n",
    "GPT_DEPLOYMENT_NAME = \"gpt-4o\"     # e.g. \"gpt-35-turbo\" or \"gpt-4\" or your custom Azure deployment\n",
    "\n",
    "# Create clients\n",
    "credential = AzureKeyCredential(AZURE_SEARCH_KEY)\n",
    "\n",
    "# Index client (to create, update, and delete indexes)\n",
    "search_index_client = SearchIndexClient(endpoint=AZURE_SEARCH_ENDPOINT, credential=credential)\n",
    "\n",
    "# Search client (to add documents, query, etc.)\n",
    "search_client = SearchClient(endpoint=AZURE_SEARCH_ENDPOINT, index_name=INDEX_NAME, credential=credential)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2. DATA PREPARATION & CHUNKING\n",
    "# ----------------------------\n",
    "\n",
    "def chunk_text_by_paragraphs(text: str, max_chars: int = 500) -> List[str]:\n",
    "    \"\"\"\n",
    "    Chunk text into segments. Preserves paragraphs if under max_chars; otherwise splits them.\n",
    "    \"\"\"\n",
    "    paragraphs = text.split(\"\\n\\n\")\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "\n",
    "    for para in paragraphs:\n",
    "        if len(current_chunk) + len(para) <= max_chars:\n",
    "            if not current_chunk:\n",
    "                current_chunk = para\n",
    "            else:\n",
    "                current_chunk += \"\\n\\n\" + para\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = para\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Example data\n",
    "documents_data = [\n",
    "    {\n",
    "        \"id\": \"doc1\",\n",
    "        \"title\": \"Azure AI Search Overview\",\n",
    "        \"url\": \"https://docs.microsoft.com/en-us/azure/search\",\n",
    "        \"text\": \"\"\"Azure AI Search is a search-as-a-service solution with built-in AI capabilities for cloud apps... \n",
    "                   It provides both full-text search using BM25 and vector search using embeddings...\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc2\",\n",
    "        \"title\": \"Azure OpenAI Introduction\",\n",
    "        \"url\": \"https://docs.microsoft.com/en-us/azure/openai\",\n",
    "        \"text\": \"\"\"Azure OpenAI offers access to advanced language models like GPT, enabling developers to build intelligent apps...\n",
    "                   Embeddings allow for semantic understanding, powering advanced search solutions.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create chunks\n",
    "all_chunks = []\n",
    "for d in documents_data:\n",
    "    text_chunks = chunk_text_by_paragraphs(d[\"text\"], max_chars=500)\n",
    "    for i, chunk in enumerate(text_chunks):\n",
    "        all_chunks.append({\n",
    "            \"vector_id\": f\"{d['id']}-{i}\",\n",
    "            \"id\": d[\"id\"],\n",
    "            \"url\": d[\"url\"],\n",
    "            \"title\": d[\"title\"],\n",
    "            \"text\": chunk\n",
    "        })\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3. CREATING / UPDATING THE INDEX\n",
    "# ----------------------------\n",
    "\n",
    "def create_or_update_index(index_name: str):\n",
    "    \"\"\"\n",
    "    Create or update an index with:\n",
    "      - Fields for metadata (id, url, title, text)\n",
    "      - Two vector fields (title_vector, content_vector) using HNSW\n",
    "      - Semantic search configuration\n",
    "    \"\"\"\n",
    "\n",
    "    fields = [\n",
    "        # Non-key fields\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String),\n",
    "        SimpleField(name=\"url\", type=SearchFieldDataType.String),\n",
    "        SearchableField(name=\"title\", type=SearchFieldDataType.String),\n",
    "        SearchableField(name=\"text\", type=SearchFieldDataType.String),\n",
    "        # KEY field: unique vector_id for each chunk\n",
    "        SimpleField(name=\"vector_id\", type=SearchFieldDataType.String, key=True),\n",
    "\n",
    "        # Vector fields\n",
    "        SearchField(\n",
    "            name=\"title_vector\",\n",
    "            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "            vector_search_dimensions=1536,\n",
    "            vector_search_profile_name=\"my-vector-config\"\n",
    "        ),\n",
    "        SearchField(\n",
    "            name=\"content_vector\",\n",
    "            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "            vector_search_dimensions=1536,\n",
    "            vector_search_profile_name=\"my-vector-config\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Vector search config\n",
    "    vector_search = VectorSearch(\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=\"my-hnsw\",\n",
    "                kind=VectorSearchAlgorithmKind.HNSW,\n",
    "                parameters=HnswParameters(\n",
    "                    m=4,\n",
    "                    ef_construction=400,\n",
    "                    ef_search=500,\n",
    "                    metric=VectorSearchAlgorithmMetric.COSINE,\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"my-vector-config\",\n",
    "                algorithm_configuration_name=\"my-hnsw\",\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Semantic search config\n",
    "    semantic_search = SemanticSearch(\n",
    "        configurations=[\n",
    "            SemanticConfiguration(\n",
    "                name=\"my-semantic-config\",\n",
    "                prioritized_fields=SemanticPrioritizedFields(\n",
    "                    title_field=SemanticField(field_name=\"title\"),\n",
    "                    keywords_fields=[SemanticField(field_name=\"url\")],\n",
    "                    content_fields=[SemanticField(field_name=\"text\")]\n",
    "                ),\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create the index\n",
    "    index = SearchIndex(\n",
    "        name=index_name,\n",
    "        fields=fields,\n",
    "        vector_search=vector_search,\n",
    "        semantic_search=semantic_search\n",
    "    )\n",
    "\n",
    "    # Create or update in Azure Cognitive Search\n",
    "    try:\n",
    "        result = search_index_client.create_or_update_index(index)\n",
    "        print(f\"Index {result.name} created/updated successfully.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error creating/updating index:\", e)\n",
    "\n",
    "# Execute the creation/update\n",
    "create_or_update_index(INDEX_NAME)\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4. GENERATE EMBEDDINGS & UPLOAD DOCUMENTS\n",
    "# ----------------------------\n",
    "\n",
    "def generate_embeddings(texts: List[str]) -> List[List[float]]:\n",
    "    response = client.embeddings.create(\n",
    "        model=EMBEDDING_MODEL_NAME,\n",
    "        input=texts\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def generate_embeddings_for_docs(texts: list[str]) -> list[list[float]]:\n",
    "    # 'client' is your AzureOpenAI or OpenAI client\n",
    "    response = client.embeddings.create(\n",
    "        model=EMBEDDING_MODEL_NAME,  # e.g., \"text-embedding-ada-002\"\n",
    "        input=texts\n",
    "    )\n",
    "    # Each item.embedding is already a one-dimensional list of floats\n",
    "    # So this returns a list of lists: [[0.12, -0.08, ...], [0.09, 0.01, ...], ...]\n",
    "    return [item.embedding for item in response.data]\n",
    "\n",
    "def upload_documents(chunks: List[Dict[str, Any]]):\n",
    "    \"\"\"\n",
    "    For each chunk of data, generate embeddings for title and text, then upload to Azure Search index.\n",
    "    \"\"\"\n",
    "    # Prepare arrays for batch embedding calls\n",
    "    titles = [c[\"title\"] for c in chunks]\n",
    "    contents = [c[\"text\"] for c in chunks]\n",
    "\n",
    "    # Generate embeddings in bulk\n",
    "    title_embeddings = generate_embeddings_for_docs(titles)\n",
    "    content_embeddings = generate_embeddings_for_docs(contents)\n",
    "\n",
    "    # Build documents with vector fields\n",
    "    documents_to_upload = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        doc = {\n",
    "            \"vector_id\": chunk[\"vector_id\"],\n",
    "            \"id\": chunk[\"id\"],\n",
    "            \"url\": chunk[\"url\"],\n",
    "            \"title\": chunk[\"title\"],\n",
    "            \"text\": chunk[\"text\"],\n",
    "            \"title_vector\": title_embeddings[i],\n",
    "            \"content_vector\": content_embeddings[i]\n",
    "        }\n",
    "        documents_to_upload.append(doc)\n",
    "\n",
    "    # Upload to Azure Cognitive Search\n",
    "    try:\n",
    "        result = search_client.upload_documents(documents=documents_to_upload)\n",
    "        print(\"Upload result:\", result)\n",
    "    except Exception as e:\n",
    "        print(\"Error uploading documents:\", e)\n",
    "\n",
    "upload_documents(all_chunks)\n",
    "\n",
    "# Allow some time for indexing\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 5. RETRIEVAL\n",
    "# ----------------------------\n",
    "\n",
    "# Only the relevant modified code, using VectorizedQuery for pure vector search:\n",
    "\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "def search_query(query: str, top_k: int = 3):\n",
    "    # Generate the embedding for the query (assuming you have generate_embeddings already defined)\n",
    "    query_embedding = generate_embeddings(query)\n",
    "\n",
    "    # Construct the vector query\n",
    "    vector_query = VectorizedQuery(\n",
    "        vector=query_embedding,\n",
    "        k_nearest_neighbors=top_k,\n",
    "        fields=\"content_vector\"\n",
    "    )\n",
    "\n",
    "    # Perform the search\n",
    "    results = search_client.search(\n",
    "        search_text=None,\n",
    "        vector_queries=[vector_query],\n",
    "        select=[\"title\", \"text\", \"url\"]\n",
    "    )\n",
    "\n",
    "    # Process and return results\n",
    "    output = []\n",
    "    for result in results:\n",
    "        output.append({\n",
    "            \"title\": result[\"title\"],\n",
    "            \"text\": result[\"text\"],\n",
    "            \"url\": result[\"url\"],\n",
    "            \"score\": result[\"@search.score\"]\n",
    "        })\n",
    "\n",
    "    return output\n",
    "\n",
    "# Example usage:\n",
    "query =  \"What does Azure AI Search offer?\"\n",
    "docs = search_query(query, top_k=3)\n",
    "for doc in docs:\n",
    "    print(f\"Title: {doc['title']}\")\n",
    "    print(f\"Score: {doc['score']}\")\n",
    "    print(f\"URL: {doc['url']}\\n\")\n",
    "\n",
    "\n",
    "# 6. ANSWER GENERATION (BASIC RAG)\n",
    "# ----------------------------\n",
    "\n",
    "def generate_answer_with_context(query: str, retrieved_docs: List[Dict[str, Any]]) -> str:\n",
    "    # Combine text from retrieved docs\n",
    "    context_str = \"\\n\\n\".join(\n",
    "        [f\"Doc {i+1} (Title: {doc['title']}):\\n{doc['text']}\" for i, doc in enumerate(retrieved_docs)]\n",
    "    )\n",
    "\n",
    "    system_message = (\n",
    "        \"You are a helpful AI assistant. Please answer the user's query based on the provided context. \"\n",
    "        \"If the context does not contain the answer, say you are unsure.\"\n",
    "    )\n",
    "    user_message = f\"Question: {query}\\n\\nContext:\\n{context_str}\\n\\nAnswer:\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=GPT_DEPLOYMENT_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=300\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "answer = generate_answer_with_context(user_query, docs)\n",
    "print(\"\\nGenerated Answer:\")\n",
    "print(answer)\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 7. IMPROVEMENTS & EXAMPLES\n",
    "# ----------------------------\n",
    "\n",
    "# --- Example: Recursive Retrieval ---\n",
    "def recursive_retrieval(query: str, max_iterations: int = 2) -> str:\n",
    "    current_query = query\n",
    "    for i in range(max_iterations):\n",
    "        print(f\"--- Iteration {i+1} ---\")\n",
    "        docs = search_query(current_query, top_k=2)\n",
    "        ans = generate_answer_with_context(current_query, docs)\n",
    "        print(f\"Answer at iteration {i+1}:\\n{ans}\\n\")\n",
    "\n",
    "        # Simple approach: if we detect \"I'm not sure\" or \"unsure\", refine the query\n",
    "        if \"unsure\" in ans.lower():\n",
    "            current_query = f\"{query} (More details needed)\"\n",
    "        else:\n",
    "            return ans\n",
    "    return ans\n",
    "\n",
    "# Example usage\n",
    "final_answer = recursive_retrieval(\"Explain how to use Azure AI Search for vector search.\")\n",
    "print(\"Final Answer:\", final_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcdb682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a36e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c720341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
